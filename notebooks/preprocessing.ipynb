{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "_ = pl.Config.set_tbl_rows(10)\n",
    "_ = pl.Config.set_tbl_cols(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdpc.data import (\n",
    "    joined_dex_swaps_df,\n",
    "    joined_token_transfers_df,\n",
    "    joined_train_df,\n",
    "    joined_transactions_df,\n",
    "    test_data_df,\n",
    "    wallet_addresses_df,\n",
    ")\n",
    "\n",
    "addresses: pl.DataFrame = wallet_addresses_df()\n",
    "train_df: pl.DataFrame = joined_train_df()\n",
    "transactions_df: pl.DataFrame = joined_transactions_df()\n",
    "dex_swaps_df: pl.DataFrame = joined_dex_swaps_df()\n",
    "token_transfers_df: pl.DataFrame = joined_token_transfers_df()\n",
    "test_df: pl.DataFrame = test_data_df()\n",
    "\n",
    "# Features start with addresses\n",
    "features_df = addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique addresses in train dataset: 99067\n",
      "Number of unique addresses in test dataset: 20369\n",
      "Number of addresses that appear in both train and test: 2\n"
     ]
    }
   ],
   "source": [
    "# Print stats of unique addresses in train and test datasets\n",
    "train_addresses = train_df.select(\"address\").unique()\n",
    "test_addresses = test_df.select(\"address\").unique()\n",
    "\n",
    "print(f\"Number of unique addresses in train dataset: {train_addresses.height}\")\n",
    "print(f\"Number of unique addresses in test dataset: {test_addresses.height}\")\n",
    "\n",
    "# Check for any overlap between train and test addresses\n",
    "overlap = train_addresses.join(test_addresses, on=\"address\", how=\"inner\")\n",
    "print(f\"Number of addresses that appear in both train and test: {overlap.height}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipside Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipside_addresses_labels: pl.DataFrame = pl.read_parquet(\n",
    "    \"../data/external/flipside_address_labels.parquet\"\n",
    ")\n",
    "\n",
    "features_df = features_df.join(\n",
    "    flipside_addresses_labels,\n",
    "    on=\"address\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipside_contracts_labels: pl.DataFrame = pl.read_parquet(\n",
    "    \"../data/external/flipside_contracts_data.parquet\"\n",
    ")\n",
    "\n",
    "flipside_contracts = flipside_contracts_labels.get_column(\"address\")\n",
    "flipside_contracts_creators = flipside_contracts_labels.get_column(\"creator_address\")\n",
    "\n",
    "features_df = features_df.with_columns(\n",
    "    pl.col(\"address\").is_in(flipside_contracts).alias(\"flipside_is_contract\"),\n",
    "    pl.col(\"address\")\n",
    "    .is_in(flipside_contracts_creators)\n",
    "    .alias(\"flipside_is_contract_creator\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known Sybil Lists Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zk_cluster_list = (\n",
    "    pl.read_csv(\"../data/external/zk_cluster_list.csv\", ignore_errors=True)\n",
    "    .select(pl.col(\"Wallet Address\").alias(\"address\"))\n",
    "    .filter(pl.col(\"address\").str.starts_with(\"0x\"))\n",
    ")\n",
    "\n",
    "features_df = features_df.with_columns(\n",
    "    pl.col(\"address\")\n",
    "    .is_in(zk_cluster_list.get_column(\"address\"))\n",
    "    .alias(\"zk_cluster_list_hit\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Layer Zero wallet list\n",
    "layer_zero_wallet_list = pl.read_csv(\"../data/external/layer_zero_wallet_list.csv\")\n",
    "layer_zero_wallet_addresses = layer_zero_wallet_list.get_column(\"ADDRESS\")\n",
    "\n",
    "# Add a column indicating if the address is in the Layer Zero wallet list\n",
    "features_df = features_df.with_columns(\n",
    "    pl.col(\"address\")\n",
    "    .is_in(layer_zero_wallet_addresses)\n",
    "    .alias(\"layer_zero_wallet_list_hit\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz_provisional_sybil_list = pl.read_parquet(\n",
    "    \"../data/external/lz_provisional_sybil_list.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the LZ provisional sybil list\n",
    "lz_provisional_sybil_list = (\n",
    "    pl.read_parquet(\"../data/external/lz_provisional_sybil_list.parquet\")\n",
    "    .rename({\n",
    "        \"source\": \"lz_provisional_list_source\",\n",
    "        \"cluster\": \"lz_probisional_list_cluster\",\n",
    "    })\n",
    "    .with_columns(pl.lit(True).alias(\"lz_provisional_sybil_list_hit\"))\n",
    ")\n",
    "\n",
    "features_df = features_df.join(\n",
    "    lz_provisional_sybil_list,\n",
    "    on=\"address\",\n",
    "    how=\"left\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sybil Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.join(\n",
    "    train_df.select([\"address\", \"label\"]),\n",
    "    on=\"address\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = (\n",
    "    transactions_df.select(\n",
    "        pl.col(\"BLOCK_NUMBER\").alias(\"block_number\"),\n",
    "        pl.col(\"BLOCK_TIMESTAMP\").alias(\"block_timestamp\"),\n",
    "        pl.col(\"TX_HASH\").alias(\"tx_hash\"),\n",
    "        pl.col(\"FROM_ADDRESS\").alias(\"from_address\"),\n",
    "        pl.col(\"TO_ADDRESS\").alias(\"to_address\"),\n",
    "        pl.col(\"VALUE\").alias(\"value\"),\n",
    "        pl.col(\"TX_FEE\").alias(\"tx_fee\"),\n",
    "        pl.col(\"GAS_PRICE\").alias(\"gas_price\"),\n",
    "        pl.col(\"GAS_LIMIT\").alias(\"gas_limit\"),\n",
    "        pl.col(\"GAS_USED\").alias(\"gas_used\"),\n",
    "        pl.col(\"INPUT_DATA\").alias(\"input_data\"),\n",
    "        pl.col(\"NETWORK\").alias(\"network\"),\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"from_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"to_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_to\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_aggregations = [\n",
    "    pl.col(\"block_number\").n_unique().alias(\"unique_block_numbers\"),\n",
    "    pl.col(\"block_timestamp\").min().alias(\"min_block_timestamp\"),\n",
    "    pl.col(\"block_timestamp\").max().alias(\"max_block_timestamp\"),\n",
    "    pl.col(\"tx_hash\").n_unique().alias(\"unique_tx_hashes\"),\n",
    "    pl.col(\"value\").sum().alias(\"total_value\"),\n",
    "    pl.col(\"value\").mean().alias(\"avg_value\"),\n",
    "    pl.col(\"value\").max().alias(\"max_value\"),\n",
    "    pl.col(\"value\").min().alias(\"min_value\"),\n",
    "    pl.col(\"tx_fee\").sum().alias(\"total_tx_fee\"),\n",
    "    pl.col(\"tx_fee\").mean().alias(\"avg_tx_fee\"),\n",
    "    pl.col(\"gas_price\").sum().cast(pl.Int64).alias(\"total_gas_price\"),\n",
    "    pl.col(\"gas_price\").mean().cast(pl.Int64).alias(\"avg_gas_price\"),\n",
    "    pl.col(\"gas_limit\").sum().cast(pl.Int64).alias(\"total_gas_limit\"),\n",
    "    pl.col(\"gas_limit\").mean().cast(pl.Int64).alias(\"avg_gas_limit\"),\n",
    "    pl.col(\"gas_used\").sum().cast(pl.Int64).alias(\"total_gas_used\"),\n",
    "    pl.col(\"gas_used\").mean().cast(pl.Int64).alias(\"avg_gas_used\"),\n",
    "    pl.col(\"network\").n_unique().alias(\"unique_networks\"),\n",
    "    # pl.col(\"community\").n_unique().alias(\"unique_communities\"),\n",
    "    # # pl.col(\"community_size\").mean().alias(\"avg_community_size\"),\n",
    "]\n",
    "\n",
    "from_aggregations = [\n",
    "    pl.col(\"from_address\").n_unique().alias(\"unique_from_addresses\"),\n",
    "    # pl.col(\"passport_stamps_score\").mean().alias(\"avg_passport_stamps_score\"),\n",
    "    pl.col(\"flipside_address_name\").n_unique().alias(\"address_name_count\"),\n",
    "    pl.col(\"flipside_is_contract\").mean().alias(\"avg_flipside_is_contract\"),\n",
    "    pl.col(\"flipside_is_contract\").sum().alias(\"flipside_is_contract_count\"),\n",
    "]\n",
    "\n",
    "to_aggregations = [\n",
    "    pl.col(\"to_address\").n_unique().alias(\"unique_to_addresses\"),\n",
    "    # pl.col(\"passport_stamps_score_to\").mean().alias(\"avg_passport_stamps_score_to\"),\n",
    "    pl.col(\"flipside_address_name_to\").n_unique().alias(\"address_name_count_to\"),\n",
    "    pl.col(\"flipside_is_contract_to\").mean().alias(\"avg_flipside_is_contract_to\"),\n",
    "    pl.col(\"flipside_is_contract_to\").sum().alias(\"flipside_is_contract_count_to\"),\n",
    "]\n",
    "\n",
    "from_all_metrics_df = (\n",
    "    transactions_df.group_by([\"from_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *to_aggregations,\n",
    "        pl.col(\"tx_hash\")\n",
    "        .filter(pl.col(\"label_to\") == 1)\n",
    "        .n_unique()\n",
    "        .alias(\"num_transactions_to_sybil\"),\n",
    "        pl.col(\"to_address\")\n",
    "        .filter(pl.col(\"label_to\") == 1)\n",
    "        .n_unique()\n",
    "        .alias(\"num_unique_to_sybil_addresses\"),\n",
    "    )\n",
    "    .rename({\"from_address\": \"address\"})\n",
    ")\n",
    "\n",
    "to_all_metrics_df = (\n",
    "    transactions_df.group_by([\"to_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *from_aggregations,\n",
    "        pl.col(\"tx_hash\")\n",
    "        .filter(pl.col(\"label\") == 1)\n",
    "        .n_unique()\n",
    "        .alias(\"num_transactions_from_sybil\"),\n",
    "        pl.col(\"from_address\")\n",
    "        .filter(pl.col(\"label\") == 1)\n",
    "        .n_unique()\n",
    "        .alias(\"num_unique_from_sybil_addresses\"),\n",
    "    )\n",
    "    .rename({\"to_address\": \"address\"})\n",
    ")\n",
    "\n",
    "from_network_transactions_metrics_df = (\n",
    "    transactions_df.group_by([\"from_address\", \"network\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        pl.col(\"to_address\").n_unique().alias(\"unique_to_addresses\"),\n",
    "    )\n",
    "    .pivot(on=\"network\", index=\"from_address\")\n",
    ").rename({\"from_address\": \"address\"})\n",
    "\n",
    "to_network_transactions_metrics_df = (\n",
    "    transactions_df.group_by([\"to_address\", \"network\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        pl.col(\"from_address\").n_unique().alias(\"unique_from_addresses\"),\n",
    "    )\n",
    "    .pivot(on=\"network\", index=\"to_address\")\n",
    ").rename({\"to_address\": \"address\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEX Swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dex_swaps_df = (\n",
    "    dex_swaps_df.select(\n",
    "        pl.col(\"BLOCK_NUMBER\").alias(\"block_number\"),\n",
    "        pl.col(\"BLOCK_TIMESTAMP\").alias(\"block_timestamp\"),\n",
    "        pl.col(\"TX_HASH\").alias(\"tx_hash\"),\n",
    "        pl.col(\"ORIGIN_FROM_ADDRESS\").alias(\"origin_from_address\"),\n",
    "        pl.col(\"ORIGIN_TO_ADDRESS\").alias(\"origin_to_address\"),\n",
    "        pl.col(\"CONTRACT_ADDRESS\").alias(\"contract_address\"),\n",
    "        pl.col(\"POOL_NAME\").alias(\"pool_name\"),\n",
    "        pl.col(\"AMOUNT_IN_USD\").cast(pl.Int64).alias(\"amount_in_usd\"),\n",
    "        pl.col(\"AMOUNT_OUT_USD\").cast(pl.Int64).alias(\"amount_out_usd\"),\n",
    "        pl.col(\"SENDER\").alias(\"sender\"),\n",
    "        pl.col(\"TX_TO\").alias(\"tx_to\"),\n",
    "        pl.col(\"PLATFORM\").alias(\"platform\"),\n",
    "        pl.col(\"TOKEN_IN\").alias(\"token_in\"),\n",
    "        pl.col(\"TOKEN_OUT\").alias(\"token_out\"),\n",
    "        pl.col(\"SYMBOL_IN\").alias(\"symbol_in\"),\n",
    "        pl.col(\"SYMBOL_OUT\").alias(\"symbol_out\"),\n",
    "        pl.col(\"NETWORK\").alias(\"network\"),\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"origin_from_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"origin_to_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_to\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_aggregations = [\n",
    "    pl.col(\"tx_hash\").n_unique().alias(\"unique_tx_hashes\"),\n",
    "    pl.col(\"contract_address\").n_unique().alias(\"unique_contract_addresses\"),\n",
    "    pl.col(\"block_timestamp\").min().alias(\"min_block_timestamp\"),\n",
    "    pl.col(\"block_timestamp\").max().alias(\"max_block_timestamp\"),\n",
    "    pl.col(\"pool_name\").n_unique().alias(\"unique_pool_names\"),\n",
    "    pl.col(\"amount_in_usd\").sum().alias(\"total_amount_in_usd\"),\n",
    "    pl.col(\"amount_in_usd\").mean().alias(\"avg_amount_in_usd\"),\n",
    "    pl.col(\"amount_in_usd\").max().alias(\"max_amount_in_usd\"),\n",
    "    pl.col(\"amount_in_usd\").min().alias(\"min_amount_in_usd\"),\n",
    "    pl.col(\"amount_out_usd\").sum().alias(\"total_amount_out_usd\"),\n",
    "    pl.col(\"amount_out_usd\").mean().alias(\"avg_amount_out_usd\"),\n",
    "    pl.col(\"amount_out_usd\").max().alias(\"max_amount_out_usd\"),\n",
    "    pl.col(\"amount_out_usd\").min().alias(\"min_amount_out_usd\"),\n",
    "    pl.col(\"platform\").n_unique().alias(\"unique_platforms\"),\n",
    "    pl.col(\"platform\")\n",
    "    .value_counts()\n",
    "    .head(1)\n",
    "    .struct.field(\"platform\")\n",
    "    .first()\n",
    "    .alias(\"most_common_platform\"),\n",
    "    # pl.col(\"community\").n_unique().alias(\"unique_communities\"),\n",
    "    # pl.col(\"community_size\").mean().alias(\"avg_community_size\"),\n",
    "]\n",
    "\n",
    "from_aggregations = [\n",
    "    pl.col(\"origin_from_address\").n_unique().alias(\"unique_origin_from_addresses\")\n",
    "]\n",
    "to_aggregations = [\n",
    "    pl.col(\"origin_to_address\").n_unique().alias(\"unique_origin_to_addresses\")\n",
    "]\n",
    "\n",
    "dex_from_all_metrics_df = (\n",
    "    dex_swaps_df.group_by([\"origin_from_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *to_aggregations,\n",
    "    )\n",
    "    .rename({\"origin_from_address\": \"address\"})\n",
    ")\n",
    "\n",
    "dex_to_all_metrics_df = (\n",
    "    dex_swaps_df.group_by([\"origin_to_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *from_aggregations,\n",
    "    )\n",
    "    .rename({\"origin_to_address\": \"address\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transfers_df = (\n",
    "    token_transfers_df.select(\n",
    "        pl.col(\"BLOCK_NUMBER\").alias(\"block_number\"),\n",
    "        pl.col(\"BLOCK_TIMESTAMP\").alias(\"block_timestamp\"),\n",
    "        pl.col(\"TX_HASH\").alias(\"tx_hash\"),\n",
    "        pl.col(\"ORIGIN_FROM_ADDRESS\").alias(\"origin_from_address\"),\n",
    "        pl.col(\"ORIGIN_TO_ADDRESS\").alias(\"origin_to_address\"),\n",
    "        pl.col(\"CONTRACT_ADDRESS\").alias(\"contract_address\"),\n",
    "        pl.col(\"FROM_ADDRESS\").alias(\"from_address\"),\n",
    "        pl.col(\"TO_ADDRESS\").alias(\"to_address\"),\n",
    "        pl.col(\"AMOUNT_USD\").cast(pl.Int64, wrap_numerical=True).alias(\"amount_usd\"),\n",
    "        pl.col(\"SYMBOL\").alias(\"symbol\"),\n",
    "        pl.col(\"NETWORK\").alias(\"network\"),\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"from_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        features_df,\n",
    "        left_on=\"to_address\",\n",
    "        right_on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_to\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more aggregations (e.g: total_for_most_common_symbol, )\n",
    "\n",
    "common_aggregations = [\n",
    "    pl.col(\"tx_hash\").n_unique().alias(\"unique_tx_hashes\"),\n",
    "    pl.col(\"contract_address\").n_unique().alias(\"unique_contract_addresses\"),\n",
    "    pl.col(\"block_timestamp\").min().alias(\"min_block_timestamp\"),\n",
    "    pl.col(\"block_timestamp\").max().alias(\"max_block_timestamp\"),\n",
    "    pl.col(\"symbol\").n_unique().alias(\"unique_symbols\"),\n",
    "    pl.col(\"amount_usd\").sum().alias(\"total_amount_usd\"),\n",
    "    pl.col(\"amount_usd\").mean().alias(\"avg_amount_usd\"),\n",
    "    pl.col(\"amount_usd\").max().alias(\"max_amount_usd\"),\n",
    "    pl.col(\"amount_usd\").min().alias(\"min_amount_usd\"),\n",
    "    pl.col(\"network\").n_unique().alias(\"unique_networks\"),\n",
    "    pl.col(\"symbol\")\n",
    "    .value_counts()\n",
    "    .head(1)\n",
    "    .struct.field(\"symbol\")\n",
    "    .first()\n",
    "    .alias(\"most_common_symbol\"),\n",
    "]\n",
    "\n",
    "to_aggregations = [\n",
    "    pl.col(\"to_address\").n_unique().alias(\"unique_to_addresses\"),\n",
    "]\n",
    "\n",
    "from_aggregations = [\n",
    "    pl.col(\"from_address\").n_unique().alias(\"unique_from_addresses\"),\n",
    "]\n",
    "\n",
    "token_transfers_from_all_metrics_df = (\n",
    "    token_transfers_df.group_by([\"from_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *to_aggregations,\n",
    "    )\n",
    "    .rename({\"from_address\": \"address\"})\n",
    ")\n",
    "\n",
    "token_transfers_to_all_metrics_df = (\n",
    "    token_transfers_df.group_by([\"to_address\"])\n",
    "    .agg(\n",
    "        *common_aggregations,\n",
    "        *from_aggregations,\n",
    "    )\n",
    "    .rename({\"to_address\": \"address\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = (\n",
    "    features_df.join(\n",
    "        from_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_from_all\",\n",
    "    )\n",
    "    .join(\n",
    "        to_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_to_all\",\n",
    "    )\n",
    "    .join(\n",
    "        from_network_transactions_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_from_network\",\n",
    "    )\n",
    "    .join(\n",
    "        to_network_transactions_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_to_network\",\n",
    "    )\n",
    "    .join(\n",
    "        dex_from_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_dex_from_all\",\n",
    "    )\n",
    "    .join(\n",
    "        dex_to_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_dex_to_all\",\n",
    "    )\n",
    "    .join(\n",
    "        token_transfers_from_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_token_transfers_from_all\",\n",
    "    )\n",
    "    .join(\n",
    "        token_transfers_to_all_metrics_df,\n",
    "        on=\"address\",\n",
    "        how=\"left\",\n",
    "        suffix=\"_token_transfers_to_all\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "\n",
    "features_df = features_df.with_columns(\n",
    "    pl.min_horizontal(features_df.select(cs.datetime()).columns).alias(\n",
    "        \"first_interaction\"\n",
    "    ),\n",
    "    pl.max_horizontal(features_df.select(cs.datetime()).columns).alias(\n",
    "        \"last_interaction\"\n",
    "    ),\n",
    ").with_columns(\n",
    "    (pl.col(\"last_interaction\") - pl.col(\"first_interaction\"))\n",
    "    .dt.total_days()\n",
    "    .alias(\"interaction_duration\"),\n",
    "    (pl.datetime(2025, 4, 26) - pl.col(\"first_interaction\"))\n",
    "    .dt.total_days()\n",
    "    .alias(\"days_since_first_interaction\"),\n",
    "    (pl.datetime(2025, 4, 26) - pl.col(\"last_interaction\"))\n",
    "    .dt.total_days()\n",
    "    .alias(\"days_since_last_interaction\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Same for token transfers and dex swaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns that have only nulls in the train set\n",
    "train_df = features_df.filter(pl.col(\"split\") == \"train\")\n",
    "train_null_cols = [\n",
    "    col\n",
    "    for col in train_df.columns\n",
    "    if (train_df[col].is_null().sum() == train_df.height)\n",
    "]\n",
    "\n",
    "features_df = features_df.drop(train_null_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ratios\n",
    "# TODO: Number of nulls in the row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shrink_to_fit().write_parquet(\n",
    "    \"../data/processed/features_df.parquet\", compression=\"zstd\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
